### 13장 동시성 성능 기법
#### 병렬처리 소개
- 데이터 병렬성
  - 큰 데이터 풀에서 작동하는 단일의 대규모 작업을 더 작은 단위로 세분화하는 것
- 작업 병렬성
  - 서로 다른 작업을 여러 프로세서에 나누어 실행하는 것
  - 자바에서는 스레드와 Executor 객체를 사용하여 이를 구현할 수 있다.
- 암달의 법칙
  - T(N) = S + (1/N) * (T-S)
    - 직렬 실행이 필요한 부분을 S, 작업에 필요한 전체 시간을 T라고 한다.
    - 프로세서의 수를 N이라하면 T(N)은 프로세서 수만큼 실행된 시간이며 T-S는 동시 실행할 수 있는 부분이며 N개의 프로세스를 고르게 분배할 수 있는 경우의 계산식
  - 하지만 작업의 복잡성이 증가하게 되고, 결국 일부 순차적 처리와 통신 오버헤드가 다시 발생
- 기본적인 자바 동시성
  ```java
  public class Counter {
      private int i = 0;
      public int increment() {
          i += 1;
          return i;
      }
  }
  ```
  - 스레드는 메서드에 진입할 때마다 개별적인 평가 스택을 갖게 되며 실제 충돌할 수 있는 부분은 필드에 대한 연산이다.
    - (힙은 모든 스레드가 공유)
  - volatile
    - volatile을 사용하면 값이 항상 캐시에서 다시 읽히도록 강제되어 다른 스레드에도 모든 업데이트를 보장한다.
    - 하지만 앞서 설명한 업데이트 손실 문제는 해결하지 못한다.
  - synchronized 를 사용하여 단순한 값의 업데이트를 제어할 수 있다.
    - 하지만 동기화를 사용하면 프로그램 속도가 느려질 수 있기 때문에 코드베이스를 병렬화하려는 모든 시도에는 추가적인 복잡성의 이점이 충분히 증명될 수 있도록 성능 테스트가 뒷받침되어야 한다.
#### 자바 메모리 모델의 이해
- 공유 상태에 접근하는 모든 곳에서, 플랫폼은 자바 메모리 모델이 제시하는 보장을 준수하도록 한다.
- 강한 메모리 모델: 모든 코어가 언제나 동일한 값을 본다.
  - 메모리에 대한 쓰기 반영 방식과 동일하게 동작
  - 캐시 무효화 알림이 메모리 버스를 가득 채우게 되어, 메인 메모리와 실질적인 데이터 전송속도가 급격히 떨어진다.
- 약한 메모리 모델: 코어마다 서로 다른 값을 볼 수 있으며, 이러한 상황이 발생할 시점을 제어하는 특별한 캐시 규칙 존재
  - Java 메모리 모델
    - 선행 발생: 한 이벤트가 다른 이벤트보다 확실히 먼저 발생
    - 동기화 관계: 해당 이벤트가 객체의 메모리 보기를 주 메모리와 동기화하도록 만든다.
    - 순차 실행: 실행중인 스레드 외부에서는 명령어가 순차적으로 실행되는 것처럼 보인다.
    - 선 해제 후 획득: 한 스레드가 잠금을 해제하면 다른 스레드가 이를 획득하기 전에 반드시 해제가 완료
  - synchronized 키워드는 이를 유지
#### 동시성 라이브러리 구축
- java.util.concurrent 라이브러리는 자바에서 멀티 스레드 애플리케이션을 작성하는 작업을 훨씬 쉽게 만들어준다.
- 스레드 핫 성능을 얻는다.
  - 스레드가 대부분의 시간을 실행에 사용하고 동일한 구조에서 작업을 수행하는 다른 스레드와 경쟁하지 않은 동시성 프로파일 의미 
- 구축 범위: 잠금과 세마포어, 래치, 원자적 연산 (atomic), 실행자 (executor), 차단 큐
- 원자적 연산 또는 비교와 교환
  - AtomicInteger는 더하기, 증가, 감소와 같은 복합 연산을 제공하며 get()과 결합하여 결과 반환
  - volatile의 확장이지만, 더 유연
  - 기대하는 현재 값과 원하는 새로운 값이라는 두개의 값을 사용하여 메모리 위치(포인터)와 함께 동작
  - 원자적 연산은 잠금이 필요 없으며 교착상태에 빠질 수 없다.
- 잠금과 반복 잠금
#### 동시성 라이브러리 요약
- java.util.concurrent 락
  ```java
  lock(): 락 획득, 락을 사용할 수 있을 때까지 블로킹
  newCondition(): 락에 조건을 추가해 유연하게 사용가능
  ex. await(), signal() 등을 통해 특정 조건동안 대기
  tryLock(): 락 획득하려고 시도, 락을 사용할 수 없는 경우에도 계속 처리 진행가능
  unlock(): 락 해제
  ```
  - LockSupport
    - 스레드를 대기 또는 재개할 수 있는 메서드 제공
    - 스레드에게 permit 발급, 없으면 대기
    - 세마포어와 비슷하지만 한 가지 퍼밋만 발급
    - 퍼밋을 받지 못한 경우 잠시 파킹, 유효한 퍼밋을 받을 수 있을 때 다시 언파킹
    - while (!canProceed()) { ... LockSupport.park(this); }
- 읽기/쓰기 잠금
  - 읽기 스레드 때문에 나머지 읽기 스레드를 블로킹하느라 불필요한 시간을 허비하는 문제 발생
  - ReentrantReadWriteLock 클래스의 ReadLock, WriteLock을 제공하며 쓰기 작업에서 차단
  - 스레드가 도착한 순서대로 처리되지만 성능 저하 가능
- 세마포어
  ```
  new Semaphore(2, true): permit 2개, 공정 모드로 생성
  비공정모드: 무한정 리소스 독점 가능
  acquire(): permit 수 감소, 더 이상 permit이 없다면 블로킹
  release(): 퍼밋 반납, 대기 중인 스레드에게 퍼밋 전달
  ```
  - 풀 스레드나 DB 접속 객체 등 여러 리소스의 엑서스를 허용하는 기술 제공, 정해진 수량의 퍼밋으로 엑세스 제어
  - 뮤텍스와 비교
    - 퍼밋이 하나 뿐이라면 뮤텍스와 동등하나 뮤텍스는 뮤텍스가 걸린 스레드만 해제 가능, 세마포어는 비소유 스레드도 해제 가능하다
- 동시 컬렉션
  - ConcurrentHashMap
    - 버킷/세그먼트로 분할된 구조
    - 각 세그먼트는 자체 락킹 정책을 가질 수 있어 쓰기가 필요한 한 세그먼트만 락을 걸 수 있음
  - CopyOnWriteArrayList, CopyOnWriteArraySet
    - 데이터를 변경할 때 배킹 배열 사본 생성
    - 기존 이터레이터는 예전 배열 계속 탐색 가능
    - 예전 배열 사본의 레퍼런스가 없게 되면 가비지 수집 대상
    - 읽는 횟수가 많을 때 잘 작동
- 래치와 배리어
  - 순차적으로 진행되는 것이 이상적인 경우 래치를 쓰는 것이 좋다.
  - countdown() 호출 시 카운트 값은 1마다 감소하고, 0에 도달하면 await() 함수에 매여 있던 스레드가 모두 해제되어 처리를 재개한다.
  - 결과가 0이 되면 해당 래치는 재사용할 수 없다는 점을 주의하자

#### 실행기와 작업 추상화
- java.util.concurrent 패키지의 기능을 사용하여 적절한 수준의 추상화를 통해 동시성 프로그램을 수행해야 한다.
  - 스레드를 효율적으로 유지하면 더 나은 스레드 핫 성능을 얻을 수 있다.
  - 스레드가 차단되거나 대기상태에 머무르지 않고 지속적으로 실행될 수 있도록 하는 것이 중요
- 비동기 실행 소개
  - Callble<V>.call()
    - 자바에서 작업 추상화 충족하는 방법 중 하나
    - V타입의 값을 반환하고 결과를 계산할 수 없는 경우 예외를 던진다.
  - ExecutorService는 submit 메서드와 그 오버로드를 통해 Runnable, Callable을 실행할 수 있다.
    - submit 메서드는 Future<V>를 리턴
  - Excutors 도우미 클래스는 팩토리 메서드를 제공하며 일반적인 방법이 있다.
    - newFixedThreadPool(int nTrheads)
      - 고정 크기의 스레드 풀을 갖는 ExecutorService 생성
    - newCachedTreadPool()
      - 필요에 따라 새로운 스레드를 생성하고 가능한 경우 기존 스레드를 재사용하는 ExecutorService 생성 (생성한 스레드는 60초 동안 유지)
    - newSingleThreadExecutor()
      - 단일 스레드로 실행되는 ExecutorService 생성
    - newScheduledThreadPool(int corePoolSize)
      - 미래의 특정 시점에 작업을 실행할 수 있도록 추가적인 메서드 제공
- executorService 선택
  - 적절한 ExeuctorService를 선택하면 비동기 처리를 효과적으로 제어할 수 있으며, 스레드 풀 내에 수를 올바르게 선택하면 성능 향상을 얻을 수 있다.
  - ThreadFactory를 제공하여 스레드 속성을 설정할 수 있도록 한다.
    - 이름, 데몬 상태, 스레드 우선순위 등의 속성
- 포크/조인
  ```java
  public class ForkJoinExample {
      public static void main(String[] args) {
          ForkJoinPool pool = new ForkJoinPool();
          FactorialTask task = new FactorialTask(10);
          Integer result = pool.invoke(task);
          System.out.println("Factorial of 10 is: " + result);
      }
  
      static class FactorialTask extends RecursiveTask<Integer> {
          private final int n;
          FactorialTask(int n) { this.n = n; }
  
          @Override
          protected Integer compute() {
              if (n == 1) return 1;
              FactorialTask subTask = new FactorialTask(n - 1);
              subTask.fork();
              return n * subTask.join();
          }
      }
  }
  ```
  - 자바는 개발자가 직접 스레드를 제어하고 관리할 필요 없이 사용할 수 있는 동시성 처리 방식 제공
  - 그 중 하나가 Fork/Join 프레임워크로 해당 프레임워크는 ExecutorService의 새로운 구현체인 ForkJoinPool 기반
    - 세분화된 작업을 효율적으로 처리할 수 있다.
    - 작업 훔치기 알고리즘 구현
  - 큰 작업을 작은 단위로 분할(Fork)해서 여러 스레드가 동시에 처리하고, 결과를 합쳐서(Join) 최종 결과를 만드는 방식으로 동작
  - 주요 개념과 특징
    - Fork: 하나의 큰 작업을 재귀적으로 더 작은 하위 작업들로 나눕니다. 이 하위 작업들은 병렬로 실행될 수 있습니다.
    - Join: 분할된 하위 작업들이 모두 완료되면, 각각의 결과를 합쳐서 하나의 최종 결과로 만듭니다.
    - Work Stealing: 각 스레드는 자신의 작업 큐를 가지고 있다가, 일이 끝나면 다른 바쁜 스레드의 큐에서 작업을 훔쳐와서 처리
      - 이를 통해 작업 부하가 자동으로 균등하게 분배되어 리소스를 최대한 활용할 수 있습니다.
    - 동적 스레드 관리: ForkJoinPool은 CPU 코어 수에 맞춰 동적으로 풀을 관리하고, 작업 처리량에 따라 스레드를 유연하게 할당
      - 사용자가 병렬성 수준(몇 개의 스레드를 쓸 것인지)도 직접 지정할 수 있습니다
  - 일반 ThreadPool 과 비교
    - 작업 분배
      - ThreadPool: 중앙 큐에서 순차 분배
      - ForkJoinPool: 각 스레드가 자신만의 큐 + 워크 스틸링
    - 병렬 처리
      - ThreadPool: 스레드 수 고정
      - ForkJoinPool: CPU 코어 수에 맞춰 동적, 자동 조정
    - 적합한 작업
      - ThreadPool: I/O, 네트워크
      - ForkJoinPool 대규모 데이터, 병렬 계산, 재귀적 분할 작업
    - 주요 메서드
      - ThreadPool: execute(), submit()
      - ForkJoinPool: fork(), join(), invoke()
- 병렬 스트림
  - parallelStream은 데이터를 병렬로 처리하고 결과를 다시 결합할 때 사용할 수 있다.
  - Spliterator를 이용해 작업을 분할하고 공통 포크/조인 풀에서 연산 실행
    - 병렬 처리가 쉬운 문제를 다룰 때 유용

#### 가상 스레드
- 자바 21부터 가상스레드 도입
- 가상 스레드 소개
  - 하나의 자바 스레드는 정확히 하나의 플랫폼 스레드라는 규칙 적용
    - Thread.start() 호출하면 운영체제의 스레드 생성 시스템 호출(linux clone())
    - 스레드 별 stack segment를 갖으며 스레드가 종료될 때까지 반환되지 않는다.
    - 즉, linux x64 환경에서 사용자 공간 스택 크기가 1mb로 설정되어 있어 스레드가 20,000개 생성되면 20gb 메모리가 필요
    - 이는 스레드 병목 문제
  - 이를 해결하기 위한 것이 바로 가상 스레드
    - 스레드를 운영 체제가 아닌 JVM에서 관리
    - 전용 플랫폼 스레드가 없으며 캐리어 스레드 풀을 공유
    - 스레드 세그먼트의 정적 할당을 더 유연한 모델로 대체
    - (적어도 일부) I/O를 수행하는 작업을 위해 설계
  - 핵심 특징
    - 경량성: 가상스레드는 기존 OS 스레드(플랫폼 스레드)와 달리, 매우 작은 메모리(200~300B 수준)만을 필요
      - 수만~수백만 개의 생성이 가능합니다.
    - JVM 스케줄링: JVM 내부 스케줄러(주로 ForkJoinPool)에서 관리·스케줄링
      - 이로 인해 컨텍스트 스위칭 비용이 획기적으로 절감됩니다.
    - 플랫폼 스레드와의 연결: 여러 가상스레드가 하나의 플랫폼 스레드에 번갈아 매핑되어 실행
      - 실제 CPU는 플랫폼 스레드(캐리어 스레드)가 사용하고, 가상스레드는 그 위에서 논리적으로 동작합니다.
    - 블로킹 작업 대응: 가상스레드가 블로킹(예: I/O, sleep)에 도달하면, 해당 플랫폼 스레드는 블로킹된 가상스레드를 힙 영역에 잠시 저장(park)하고, 즉시 다른 가상스레드로 교체해 작업 효율을 극대화
  - 동작 원리 요약
    - 가상스레드는 OS·플랫폼 스레드와 1:1 매핑되지 않음.
    - JVM의 스케줄러(예: ForkJoinPool)는 각 가상스레드의 작업(runContinuation 등)을 플랫폼 스레드의 작업 큐에 넣음.
    - 플랫폼 스레드는 자신에게 매핑된 여러 가상스레드를 번갈아 실행하며, 필요 시 다른 플랫폼 스레드와 작업을 나누기도 함.
      - work stealing
    - I/O나 sleep 같은 블로킹 상황이 생기면, 해당 플랫폼 스레드는 해당 가상스레드를 중단(park)하고, 바로 다음 가상스레드 실행으로 넘어감.
    - 이를 통해 기존 대비 훨씬 더 많은 동시 실행 쓰레드 수를 지원, 효율적인 리소스 활용 가능
  - 제한 사항
    - 가상 스레드는 blocking I/O 호출이 발생할 때만 양보하며 선점은 없다.
    - 네이티브 인터페이스 호출, synchronized 키워드는 가상 스레드를 캐리어 스레드에 고정 시켜 unmount 방지
      - 가상 스레드가 스케줄링 될 때, 플랫폼 스레드에 마운트되거나 할당
      - 보통 언마운트된 가상 스레드갸 I/O를 기다리거나 코드 실행을 완료하기위한 차단될 때 발생하며, 이 과정에서 플랫폼 스레드는 해제되어 다른 작업을 사용할 수 있게 된다.
      - 하지만 이런 방식으로 가상 스레드를 고정하면, 이러한 언마운팅이 불가능해지고, 결국 자원 문제와 예기치 않은 차단 현상 초래 가능
    - 가상 스레드는 객체 풀 패턴과 잘 호환되지 않는다.
    - 가상 스레드는 수명이 짧도록 설계되어 기본적인 캐싱 기술은 재사용할 수 없는 가비지 객체에 대한 약한 참조를 유지하는 결과를 초래할 수 있다.

### 14장 분산시스템 기법
#### 기본적인 분산 데이터 구조
#### 합의 프로토콜
#### 분산시스템 예제

