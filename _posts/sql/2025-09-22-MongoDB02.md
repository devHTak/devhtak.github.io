### 05. 인덱스

#### 디스크 읽기 방식
- 랜덤 I/O(Random I/O)
  - 데이터를 비연속적인(물리적으로 떨어진) 위치에서 임의로 읽거나 쓰는 작업이다.
  - 디스크 헤드가 여러 위치로 이동해야 하므로, 작업당 seek time(탐색 시간)·latency가 크게 증가한다.
  - 인덱스 기반 탐색, WHERE 조건 조회, 특정 레코드 단건 접근, 임의 위치 갱신·삭제 등에서 주로 발생한다.
  - HDD에서는 랜덤 I/O가 매우 느리며, SSD는 그 차이가 적지만 throughput(처리량)은 여전히 낮은 편이다.
    - ex) 인덱스 레인지 스캔, 키 값 하나씩 랜덤 조회 등.
- 순차 I/O(Sequential I/O)
  - 물리적으로 연속된(붙은) 위치에서 데이터를 순서대로 읽거나 쓴다.
  - 디스크 헤드를 거의 이동시키지 않고, 한 번 seek한 뒤 연달아 데이터를 읽거나 쓸 수 있다.
  - 전체 테이블 스캔, 대량 정렬·그룹화, 연속 블록 덤프 등에서 발생.
  - 대용량 데이터 일괄 처리에 유리하며, HDD·SSD 모두에서 랜덤 I/O보다 월등히 빠르다.
  - ex) 풀 테이블 스캔(모든 로우 직접 읽기), 파일 연속 저장 등.
- 성능 개선 관점
  - DB 쿼리 성능을 높이려면 랜덤 I/O를 최소화하고, 순차 I/O가 많이 발생하도록 데이터 구조·쿼리를 최적화하는 것이 바람직하다.
  - 이는 꼭 필요한 데이터만 읽고 쓰도록 설계하거나, 액세스 패턴을 연속적으로 유지하는 방식으로 이뤄질 수 있다.

#### 인덱스란?
- 모든 데이터를 뒤져서 원하는 결과를 가져오는 데에 시간이 걸리기 때문에 컬럼과 레코드가 저장된 위치를 key-value 관리
  - DBMS의 인덱스도 컬럼의 값을 주어진 순서로 미리 정렬해서 가지고 있다.
  - SortedList: DBMS의 인덱스와 동일한 자료 구조로 정렬된 상태 유지
    - 저장하는 과정은 복잡하고 느리지만 원하는 값을 빠르게 찾을 수 있다.
  - ArrayList: 데이터 파일과 동일한 자료 구조 사용로 저장된 순서 그대로 유지 
- 인덱스는 데이터 저장 방식에 따라 분류할 수 있으며 대표적으로 B-Tree 인덱스, Hash 인덱스가 있다
- 데이터 중복 여부에 따라 unique index, non-unique index로 구분할 수 있다

#### MongoDB 인덱스의 개요
- 클러스터링 인덱스
  - 클러스터링 인덱스는 기본 키 값을 기준으로 데이터가 물리적으로 정렬 저장되는 인덱스 방식이다.
  - MongoDB 인덱스 구조와 차이점
    - MongoDB는 모든 인덱스를 B-Tree 기반으로 구현하며, 인덱스는 키와 도큐먼트 위치(논리적 주소)를 별도로 저장한다.
    - 도큐먼트 저장 위치와 인덱스는 분리되어 있다.
      - 도큐먼트가 물리적으로 정렬되는 구조가 아니고, 인덱스가 클러스터된 데이터를 포함하지 않는다.
    - 따라서 기본 키(_id) 인덱스도 단순 유니크 인덱스일 뿐, 클러스터링과 같은 기능은 하지 않는다.
  - 지원하지 않는 이유
    - MongoDB는 도큐먼트 지향 DB로, 각 도큐먼트는 BSON 형태로 저장되고, 크기와 구조가 가변적이어서 물리적 정렬 저장이 어렵다.
    - 도큐먼트 크기 변동과 메모리 조각화 현상 때문에 클러스터링 인덱스처럼 물리적 위치 재정렬을 실시간으로 유지하는 게 비효율적이다.
    - 대신 인덱스는 빠른 탐색을 위한 별도의 구조로 유지하고, 도큐먼트는 자유롭게 분산·저장한다.
- 인덱스 내부(WiredTiger 스토리지 엔진 기준)
  - B+Tree 기반: WiredTiger 인덱스는 B+Tree 자료구조를 사용
    - 이는 계층적 구조(루트 노드, 내부 노드, 리프 노드)로 구성된다. B+Tree는 빠른 탐색, 삽입, 삭제를 지원한다.
  - 레코드 ID: 인덱스 키 엔트리는 각 도큐먼트에 고유 식별자인 Record-Id를 할당한다.
    - Record-Id는 64비트 정수로 컬렉션 단위로 별도 자동 증가 값을 사용하며, 도큐먼트 위치와 논리적으로 연결된다.
  - MVCC 지원: WiredTiger는 다중 버전 동시성 제어(MVCC)를 지원
    - 인덱스는 여러 버전을 관리하며, 읽기 작업은 특정 시점의 일관된 버전을 참조하고, 쓰기 작업은 새 버전을 생성한다.
  - 저널링 및 체크포인트: 인덱스 구조 변경(노드 분할, 병합 등)은 원자적으로 이루어져야 하며, 저널 로그를 통해 내구성이 보장된다.
    - 변경된 인덱스는 메모리에서 빠르게 처리 후 체크포인트 시 디스크에 반영되어 랜덤 I/O를 순차 I/O로 변환해 성능을 향상시킨다.
  - 압축: 인덱스는 기본적으로 프리픽스 압축(prefix compression) 지원
    - 인덱스 키들의 공통 접두사 부분을 압축해 저장 공간을 절감한다.
- 로컬 인덱스
  - 샤딩 클러스터 환경에서 각 샤드가 자신이 저장하고 있는 도큐먼트에 대해서만 관리하는 인덱스를 의미한다.
  - 특징
    - 각 샤드는 자신의 데이터에 대해 별도로 인덱스를 생성·관리한다.
    - 인덱스가 저장하고 있는 도큐먼트들은 해당 샤드 내에 물리적으로 존재하는 데이터에 한정된다.
    - 애플리케이션 레벨에서 전역 유니크성을 보장해야 한다.
      - 샤딩 환경에서 유니크 인덱스나 프라이머리 키 인덱스가 있다면 반드시 샤드 키를 포함하는 등의 방법 필요
  - 의미
    - 샤딩된 컬렉션은 데이터가 여러 샤드에 분산 저장되므로, 인덱스 역시 각 샤드별로 로컬하게 존재하고 관리된다.
    - 샤드간의 인덱스 통합 구조가 아니라 각자 독립적인 인덱스를 갖는다.
  - 제한 사항
    - 전역 유니크 인덱스는 기본적으로 지원하지 않으며, 이를 위해 샤드 키와 연계하거나 외부에서 중복 체크를 해야 한다.
    - 인덱스가 많아질수록 밸런싱 속도와 시스템 부하에 영향을 줄 수 있다
- 인덱스 키 엔트리 자료구조
  - 키 값(Key): 인덱스를 생성할 때 지정한 필드의 값이 인덱스 키로 사용되며 BSON 타입으로 복합 인덱스인 경우 여러 필드가 조합되어 하나의 키를 형성
  - Record-Id (도큐먼트 위치 정보): 각 인덱스 키와 연결된 도큐먼트의 저장 위치를 의미한다.
    - MongoDB 내부적으로는 Record-Id로 관리되며, 도큐먼트의 논리적 위치 혹은 물리적 위치를 가리킨다.
  - 노드 종류
    - 브랜치 노드: 하위 노드들을 가리키는 인덱스 엔트리들을 포함한다.
    - 리프 노드: 실제 키와 Record-Id 쌍으로 구성되어, 도큐먼트 바로 접근이 가능하다.
  - 정렬: 키 값들은 B-Tree 특성상 정렬되어 저장되어 있어 빠른 탐색과 범위 쿼리가 가능하다.
  - 멀티 키 인덱스: 배열 필드를 인덱스할 때 하나의 도큐먼트에 여러 키 엔트리가 생성될 수 있다.
  - 동작 및 특징: 인덱스는 빠른 검색을 위해 키 값에 따라 정렬과 트리 탐색 구조를 유지한다.
    - Record-Id를 통해 인덱스에서 도큐먼트로 빠르게 접근 가능하며, 추가/삭제 시 B-Tree 노드가 분할/병합된다.
    - BSON 기반의 가변 길이 키 값을 처리하기 때문에 인덱스 키 엔트리 크기가 달라질 수 있다.

#### B-Tree 인덱스

#### Hash 인덱스

#### 멀티 키 인덱스

#### 인덱스 속성
- 프라이머리 키와 세컨드리 인덱스
  - 모든 컬렉션이 반드시 프라이머리 키를 갖으며 MongoDB의 프라이머리 키 필드는 사용자가 필드의 이름을 결정할 수 없다
    - 사용자가 필드의 이름을 결정할 수 없고 _id라는 이름의 도큐먼트에 저장해야 한다
  - 그 외에 인덱스는 세컨드리 인덱스라 한다.
  - 컬렉션이 샤딩 된 경우에는 각 샤드간 프라이머리 키 값의 중복 체크를 응용 프로그램에서 처리해야 한다
  - 서브 도큐먼트를 인덱스 키로 사용하는 경우 서브 도큐먼트의 필드 개수와 필드 이름, 값까지 같아야 같은 값으로 판단
    - 필드 개수나 순서와 관계없이 검색하고자 한다면 각 팔디를 조건에 명시하면 된다. 하지만 이렇게 할 경우 인덱스 조회를 못함
    - COLLSCAN 발생
    ```
    $ db.users.insert({"_id": {"birth_date": "1980-01-01", "name": "matt"}})
    $ db.users.insert({"_id": {"name": "matt", "birth_date": "1980-01-01"}})
    
    $ db.users.find({"_id.birth_date": "1980-01-01", "_id.name": "matt"})
    ```
- 유니크 인덱스
  ```
  $ db.unique.createIndex({"age": 1}, {unique: true})
  ```
  - 유니크 인덱스라고 해서 NULL 값이 제한되는 것은 아니며 프라이머리 키는 기본적으로 유니크 속성 부여
    - 하지만 NULL 값이 2개 이상일 수 없다.
  - MongoDB에는 유니크 인덱스는 도큐먼트 간의 중복된 값을 체크하지만 도큐먼트 내에서 중복된 값을 체크하지 않는다.
    - 서브 도큐먼트를 배열로 갖으면, 해당 필드를 유니크 인덱스가 있지만, 같은 번호를 저장해도 에러가 발생하지 않는다.
    ```
    $ db.users.createIndex({"contacts.no": 1}, {unique: true})
    $ db.users.insert({ name: "matt", contacts: [
      {type:"office", no: {"010-0000-0000"}, {type:"mobile", no: {"010-0000-0000"}}]});
    ```
  - 샤딩을 적용하지 않으면 유니크 인덱스를 생성할 수 있지만 샤딩에 경우 샤드키를 선행 필들르 가지는 인덱스에만 유니크 인덱스를 생성할 수 있다
- Partial 인덱스
  - Partial Index(부분 인덱스)는 컬렉션 내 도큐먼트 중에서 특정 조건에 부합하는 도큐먼트에 대해서만 인덱스를 생성
  - 주요 특징
    - 조건부 인덱스 생성: 인덱싱할 때 partialFilterExpression 옵션에 정의한 조건을 만족하는 도큐먼트만 인덱싱된다.
      ```
      $ db.collection.createIndex({score:1}, {partialFilterExpression:{score:{$gte:100}}})
      // score가 100 이상인 도큐먼트만 인덱스 엔트리 생성.
      ```
    - 스토리지 절약 및 성능 최적화: 전체 데이터가 아닌 일부 조건을 만족하는 데이터에만 인덱싱되므로 인덱스 크기가 대폭 줄고, 인덱스 관리(생성/갱신) 비용이 감소한다.
    - 복합 조건 가능: 필드 존재 여부($exists), 비교 연산($gt, $gte, $lt, $lte 등), 타입($type), 그리고 상위에 $and 연산자를 활용한 조건식도 지정할 수 있다.
  - 제약점
    - 샤드 키/Primary Key에 사용 불가: partial 인덱스는 샤드 키 인덱스나 _id(Primary Key) 인덱스는 지원하지 않는다.
    - 커버링 인덱스 제한: 쿼리가 partial 조건을 벗어나면 인덱스를 사용할 수 없고, 인덱스가 해당 쿼리를 커버하지 못함.
- Sparse 인덱스
  ```
  $ db.sparse.createIndex( {birth_date: 1}, {sparse: true} )
  ```
  - sparse index(희소 인덱스)는 인덱싱할 필드가 존재하는 도큐먼트에만 인덱스 엔트리를 생성하는 인덱스 옵션이다.
  - 핵심 특징
    - 필드 존재 조건: 인덱스 대상 필드가 컬렉션의 도큐먼트에 존재하면 인덱스 엔트리를 만들며, 해당 필드가 없는 도큐먼트는 인덱스에 포함되지 않는다.
    - NULL 값 처리 및 효율: 해당 값이 null인 경우나 필드가 아예 없는 경우 인덱싱하지 않아 저장 공간과 인덱싱 비용이 줄어든다.
      - 희소 인덱스는 유니크 인덱스와 조합할 경우, 필드가 없는 도큐먼트끼리의 중복을 허용한다.
    - 적용 시기: 컬렉션 내에 인덱싱 필드가 없는 도큐먼트가 상당수 있을 때, 쓸모 없는 인덱스 엔트리 생성을 방지해 효율적
  - 제약 및 주의점
    - 희소 인덱스가 걸린 필드는 쿼리 인덱스 최적화에는 좋지만, 컬렉션 전체에서 값을 반드시 커버하지 못한다.
      - 일부 쿼리 결과에 빠진 도큐먼트가 있을 수 있다.
    - 커버링 인덱스 성능 최적화가 제한될 수 있으며, 쿼리 힌트 사용 시 결과 불완전 가능성도 있다
- TTL(Time-To-Live) 인덱스
  ```
  db.logs.createIndex({ "createdAt": 1 }, { expireAfterSeconds: 3600 })
  // createdAt 기준 1시간(3600초) 후 도큐먼트 자동 삭제
  ```
  - TTL 인덱스는 컬렉션 내의 도큐먼트가 특정 시간이 지나면 자동으로 삭제되도록 하는 특수 인덱스 기능이다.
  - 핵심 특징
    - 자동 데이터 만료 및 삭제: Date 타입 필드(예: createdAt, expires 등)를 기준으로 정해진 시간이 지나면, 도큐먼트가 백그라운드에서 자동 삭제
    - 단일 필드만 적용: TTL 인덱스는 반드시 전용 날짜(Date) 필드에만 적용되며, 복합 인덱스에서는 지원하지 않는다.
    - 옵션 사용법: 인덱스 생성시 expireAfterSeconds 옵션을 명시해, 데이트 필드 기준 n초 후 도큐먼트를 삭제한다.
    - 백그라운드 동작: TTL 인덱스는 실시간이 아닌, 내부 스케줄러가 약 60초마다(최대 1분 지연) 만료 데이터를 삭제한다.
  - 활용 사례
    - 로그, 세션, 임시 인증 정보, 캐시 등 일정 시간 뒤 삭제가 필요한 데이터 관리에 많이 사용된다.
  - 주의사항
    - 타이머 기반이므로 Date 필드 값이 변경되면 TTL 타이머도 갱신된다. 대량 삭제 시 일시적으로 성능 영향을 받을 수 있다
- 외래키
  - 외래키에 대한 제약 기능을 지원하지 않는다.
  - 컬렉션이 샤딩을 가정하고 구현했기 때문에 외래 키에 대한 제약을 구현한다 하더라도 성능을 보장할 수 없기 때문
  - 외래 키에 대한 일관된 처리가 꼭 필요하다면 응용 프로그램에서 직접 구현하는 것 외에는 방법이 없다
 
### 잠금과 트랜잭션

#### 잠금
- 동시 처리 중에 발생할 수 있는 쓰레드간의 충돌 문제를 막기 위해 잠금 사용
  - Intention Lock, Multiple granularity locking(다중 레벨의 잠금) 활용
 
- MongoDB 엔진의 잠금
  - 글로벌 잠금
    - 유일하게 명시적으로 사용할 수 있는 잠금은 글로벌 잠금으로 현재 3.4 버전의 다른 모든 잠금은 전부 묵시적으로만 사용
      - 쿼리나 데이터 변경 명령이 실행되면 묵시적으로 MongoDB 서버 인스턴스에 단 하나만 있는 잠금, 이를 인스턴스 잠금이라 한다
    ```
    $ db.fsyncLock({fsync: 1, lock: true})
    $ db.fsyncUnlock() // 잠금 해제
    $ db.currentOp() // 글로벌 잠금 상태를 알 수 있다
    ```
    - fsync 옵션을 1로 설정하면 디스크에 기록되지 못한 데이터를 모두 디스크로 플러시(기록)한다
    - lock 옵션을 false로 하면 잠금을 걸지 않은 체 디스크로 플러시 한다
    - fsyncLock 은 내부적으로 쓰기 잠금이 아닌 읽기 잠금에 해당
      - 다른 컨넥션의 데이터 읽기를 막지 않으며 모든 커넥션의 데이터 저장이나 변경을 실행할 수 없다.
      - 데이터 변경 명령이 블로킹되므로 다른 읽기 쿼리도 실행하지 못한다.
  - 오브젝트 잠금
    - 2.6 버전 이하 버전의 MMAPv1 스토리지 엔진에서는 DB 수준의 잠금 사용
    - 3.0 버전 이후 MMAPv1 스토리지 엔진은 컬렉션 수준의 잠금으로 조금 더 최적화됐다.
      - 컬렉션 단위의 자금이 도입되면서 계층형 오브젝트에 대한 동시성 처리 보장을 위한 다중 레벨 잠금 방식 도입
      - S/X Lock, IS(Intent Shared) Lock, IX(Intent Exclusive) Lock 제공
    - Intent Shared Lock
      ```
      $ SELECT ... LOCK IN SHARE MODE // 테이블에는 IS-Lock이 걸리고, 실제 행(Row)은 S-Lock
      ```
      - 트랜잭션이 레코드에 공유 락(Shared Lock, S-Lock)을 걸 의도가 있음을 테이블 레벨에서 미리 표시하는 락
      - 여러 트랜잭션이 동시에 IS-Lock을 획득할 수 있다.
    - Intent Exclusive Lock
      ```
      SELECT ... FOR UPDATE, INSERT, UPDATE, DELETE
      ```
      - 트랜잭션이 레코드에 베타 락(Exclusive Lock, X-Lock)을 걸 의도가 있음을 테이블 레벨에서 미리 표시하는 락
      - 여러 트랜잭션이 동시에 IX-Lock을 획득할 수 있다.
    - 왜 의도 락이 필요한가?
      - 테이블 레벨과 행(Row) 레벨의 락이 혼재하는 환경에서, 양쪽의 락 상태를 효과적 관리
      - 충돌 시 빠르게 판단하기 위해 사용된다.
      - 한 트랜잭션이 행에 X-Lock을 걸고 있을 때, 다른 트랜잭션이 테이블 전체에 대한 X-Lock(스키마 변경 등)을 시도하면
        - IX-Lock 덕분에 바로 충돌을 감지하며, 일관성과 무결성을 유지할 수 있다
- WiredTiger 스토리지 엔진의 잠금
  - MongoDB의 IS/IX Lock 작동 방식
    - MongoDB는 글로벌, 데이터베이스, 컬렉션, 문서 등 여러 계층에서 락을 관리
      - 실제 컬렉션/도큐먼트 접근시 하위 트랜잭션의 락 목적을 상위 계층에 알리기 위해 IS/IX 락 사용
      - 컬렉션에서 문서 단위로 읽기(Shared)를 할 경우 데이터베이스와 글로벌 수준에서는 IS 락을 획득
    - 반대로, 컬렉션 또는 문서 단위로 쓰기(Exclusive)를 수행할 때 데이터베이스/글로벌 단계에서는 IX 락 획득
    - IS/IX 락은 상호 호환성(동시처리 허용)이 높다.
      - 여러 트랜잭션이 동시에 동일 데이터베이스/컬렉션에 대해 읽기 또는 쓰기 작업을 의도하는 것을 막지 않는다.
  - 활용 예시 및 자동화
    - 컬렉션 인덱스 생성 작업: 해당 컬렉션을 포함하는 데이터베이스와 글로벌에 대해 IX 락을 선점하고, 인덱스 생성 작업을 처리
    - 도큐먼트 삽입, 수정, 삭제 등: 컬렉션, 데이터베이스, 글로벌에 대해 IX 락을 먼저 획득
      - 문서에 대한 실제 X 락을 건다. 이 방식은 대규모 동시 write 작업시 경합 문제를 최소화
    - 조회 명령은 IS 락을 적용하지만 WiredTiger 스토리지 엔진의 MVCC 구조 덕분에 도큐먼트엔 실제 락을 거의 걸지 않는다.
    - 락은 사용자가 직접 명령을 통해 제어하지 않고, MongoDB 내부 엔진(WiredTiger 등)이 자동 관리
  - 운영 시 유의점
    - IS/IX 락은 테이블, 컬렉션, 데이터베이스 등 상위 레벨에 미리 락 목적을 알려 충돌·병목을 예방
    - 스키마 변경, 대량 인덱스 작업 등은 락 경합(Contestion) 문제 가능
    - 쿼리 효율화, 적절한 인덱스 설계, 데이터 구조 최적화 등을 통해 자주 발생하는 경합을 줄이는 것이 중요하다
- 잠금 Yield
  ```
  $ db.runCommand({ getParameter: '*' })
  $ db.runCommand({ setParameter:1, "internalQueryExecYieldIterations": 256 })
  // 인덱스를 갖지 않는 컬렉션 전수 검색 시 내부적으로 기본값 128개 도큐먼트를 읽을 때 yield 발생
  $ db.runCommand({ setParameter:1, "internalQueryExecYieldPeriodMS": 20 })
  // 20ms 이상 수행되면 yield 발생 default 10ms
  ```
  - 쿼리를 처리하기 위해 한번 잠금을 획득하면 쿼리의 처리가 완료될떄까지 획득할 때 잠금을 다시 해제하지 않는다.
  - 쿼리를 실행하는 도중에 잠깐 쉬었다가 쿼리의 실행을 재개하는 것을 Yield(양보)라고 한다
  - MongoDB Yield 동작 원리
    - MongoDB는 긴 쿼리 또는 대량 데이터 처리 중 일정 횟수(document 개수) 또는 시간이 경과
      - 커넥션이 가진 모든 락을 해제, CPU 자원을 놓고, OS의 스케줄러가 다시 재개할 때 락을 재획득하여 이어 처리하는 방식
  - yield를 통해 다른 커넥션에 락 양보 및 자원 선순환 처리가 가능하며, 동시성 효율이 극대화된다.
  - 주요 용도 및 한계
    - yield는 장기 실행 쿼리(인덱스 생성·삭제, 대량 데이터 처리 등)에서 시스템 전체 성능과 병목 현상을 최소화 전략
    - 대량 작업 도중 데이터가 변경될 수 있으므로, 데이터 일관성이 반드시 유지되어야 하는 트랜잭션에는 주의가 필요
    - 사용자는 직접 yield를 제어하지 못하고, 내부 엔진(WiredTiger 등)이 자동으로 관리
- 잠금 진단
  - db.currentOp()
    - 현재 실행중인 명령들의 목록을 조회
    - 각 프로세스틔 목록은 클라이언트 정보
    - 쿼리의 내용과 더불어 잠금의 내용 확인
  - r: DB 레벨의 Shared Lock (2.6) / Intention Shared Lock (3.0 이상)
  - w: DB 레벨의 Exclusive Lock (2.6) / Intention Exclusive Lock (3.0 이상)
  - R: 글로벌 Shared Lock (2.6) / Shared Lock (3.0 이상)
  - W: 글로벌 Exclusive Lock (2.6) / Exclusive Lock (3.0 이상)

#### 트랜잭션
- WiredTiger 스토리지 엔진에서 트랜잭션과 관련된 설명이 추가되었다.
  - ACID 속성에 대한 특성
    - 최고 레벨의 격리 수준은 Snapshot
    - 트랜잭션의 커밋과 체크포인트 2가지 형태로 영속성 보장
    - 커밋되지 않은 변경 데이터는 공유 캐시 크기보다 작아야 한다
  - Read Unccommited, Read Commited, Snapshot(Repeatable Read) 수준의 격리 수준 제공
- 쓰기 충돌
  - 하나의 데이터를 동시에 변경하려고 하는 상황에서는 쓰기 충돌 발생하며 변경하고자 하는 도큐먼트의 락이 있으면 업데이트 실행 취소
  - WriteConflict Exception 발생 -> 내부적으로 해당 예외에 경우 재시도 처리를 하며 어플리케이션 단에서는 모를 수 있다
- 단일 도큐먼트 트랜잭션
  - 처음부터 단일 도큐먼트의 트랜잭션만 지원하며 이는 단일 도큐먼트 변경의 원자단위 처리가 보장되는 것
    - collection 에 insert를 하면, collection -> index 0 ~ N -> OpLog 순으로 insert 진행
  - 샤딩을 고려하여 단일 샤드만 처리 가능
- 문장의 트랜잭션 처리
  ```
  $ db.users.insert( {_id: 1, name: "matt"}, {_id: 2, name: "jonathan"})
  $ db.users.update( {"name: "matt"}, {$set: {score:90}}, {multi: true})
  BEGIN
    db.users.insert( {_id: 1, name: "matt"} )
  COMMIT
  BEGIN
    db.users.insert( {_id: 2, name: "jonathan"} )
  COMMIT
  ```
  - 여러 도큐먼트가 저장되는 배치 insert, 한번에 여러 도큐먼트를 변경하는 업데이트 문장에서 트랜잭션 처리
    - Mongo에서는 작은 트랜잭션으로 쪼개져서 처리
  - 처리도중 예외가 발생해도 rollback 되지 않고 이전 처리 결과는 남게 된다 

#### 격리 수준

#### Read and Write Conern 과 Read Prefernece
