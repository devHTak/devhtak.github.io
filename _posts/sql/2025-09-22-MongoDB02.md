### 05. 인덱스

#### 디스크 읽기 방식
- 랜덤 I/O(Random I/O)
  - 데이터를 비연속적인(물리적으로 떨어진) 위치에서 임의로 읽거나 쓰는 작업이다.
  - 디스크 헤드가 여러 위치로 이동해야 하므로, 작업당 seek time(탐색 시간)·latency가 크게 증가한다.
  - 인덱스 기반 탐색, WHERE 조건 조회, 특정 레코드 단건 접근, 임의 위치 갱신·삭제 등에서 주로 발생한다.
  - HDD에서는 랜덤 I/O가 매우 느리며, SSD는 그 차이가 적지만 throughput(처리량)은 여전히 낮은 편이다.
    - ex) 인덱스 레인지 스캔, 키 값 하나씩 랜덤 조회 등.
- 순차 I/O(Sequential I/O)
  - 물리적으로 연속된(붙은) 위치에서 데이터를 순서대로 읽거나 쓴다.
  - 디스크 헤드를 거의 이동시키지 않고, 한 번 seek한 뒤 연달아 데이터를 읽거나 쓸 수 있다.
  - 전체 테이블 스캔, 대량 정렬·그룹화, 연속 블록 덤프 등에서 발생.
  - 대용량 데이터 일괄 처리에 유리하며, HDD·SSD 모두에서 랜덤 I/O보다 월등히 빠르다.
  - ex) 풀 테이블 스캔(모든 로우 직접 읽기), 파일 연속 저장 등.
- 성능 개선 관점
  - DB 쿼리 성능을 높이려면 랜덤 I/O를 최소화하고, 순차 I/O가 많이 발생하도록 데이터 구조·쿼리를 최적화하는 것이 바람직하다.
  - 이는 꼭 필요한 데이터만 읽고 쓰도록 설계하거나, 액세스 패턴을 연속적으로 유지하는 방식으로 이뤄질 수 있다.

#### 인덱스란?
- 모든 데이터를 뒤져서 원하는 결과를 가져오는 데에 시간이 걸리기 때문에 컬럼과 레코드가 저장된 위치를 key-value 관리
  - DBMS의 인덱스도 컬럼의 값을 주어진 순서로 미리 정렬해서 가지고 있다.
  - SortedList: DBMS의 인덱스와 동일한 자료 구조로 정렬된 상태 유지
    - 저장하는 과정은 복잡하고 느리지만 원하는 값을 빠르게 찾을 수 있다.
  - ArrayList: 데이터 파일과 동일한 자료 구조 사용로 저장된 순서 그대로 유지 
- 인덱스는 데이터 저장 방식에 따라 분류할 수 있으며 대표적으로 B-Tree 인덱스, Hash 인덱스가 있다
- 데이터 중복 여부에 따라 unique index, non-unique index로 구분할 수 있다

#### MongoDB 인덱스의 개요
- 클러스터링 인덱스
  - 클러스터링 인덱스는 기본 키 값을 기준으로 데이터가 물리적으로 정렬 저장되는 인덱스 방식이다.
  - MongoDB 인덱스 구조와 차이점
    - MongoDB는 모든 인덱스를 B-Tree 기반으로 구현하며, 인덱스는 키와 도큐먼트 위치(논리적 주소)를 별도로 저장한다.
    - 도큐먼트 저장 위치와 인덱스는 분리되어 있다.
      - 도큐먼트가 물리적으로 정렬되는 구조가 아니고, 인덱스가 클러스터된 데이터를 포함하지 않는다.
    - 따라서 기본 키(_id) 인덱스도 단순 유니크 인덱스일 뿐, 클러스터링과 같은 기능은 하지 않는다.
  - 지원하지 않는 이유
    - MongoDB는 도큐먼트 지향 DB로, 각 도큐먼트는 BSON 형태로 저장되고, 크기와 구조가 가변적이어서 물리적 정렬 저장이 어렵다.
    - 도큐먼트 크기 변동과 메모리 조각화 현상 때문에 클러스터링 인덱스처럼 물리적 위치 재정렬을 실시간으로 유지하는 게 비효율적이다.
    - 대신 인덱스는 빠른 탐색을 위한 별도의 구조로 유지하고, 도큐먼트는 자유롭게 분산·저장한다.
- 인덱스 내부(WiredTiger 스토리지 엔진 기준)
  - B+Tree 기반: WiredTiger 인덱스는 B+Tree 자료구조를 사용
    - 이는 계층적 구조(루트 노드, 내부 노드, 리프 노드)로 구성된다. B+Tree는 빠른 탐색, 삽입, 삭제를 지원한다.
  - 레코드 ID: 인덱스 키 엔트리는 각 도큐먼트에 고유 식별자인 Record-Id를 할당한다.
    - Record-Id는 64비트 정수로 컬렉션 단위로 별도 자동 증가 값을 사용하며, 도큐먼트 위치와 논리적으로 연결된다.
  - MVCC 지원: WiredTiger는 다중 버전 동시성 제어(MVCC)를 지원
    - 인덱스는 여러 버전을 관리하며, 읽기 작업은 특정 시점의 일관된 버전을 참조하고, 쓰기 작업은 새 버전을 생성한다.
  - 저널링 및 체크포인트: 인덱스 구조 변경(노드 분할, 병합 등)은 원자적으로 이루어져야 하며, 저널 로그를 통해 내구성이 보장된다.
    - 변경된 인덱스는 메모리에서 빠르게 처리 후 체크포인트 시 디스크에 반영되어 랜덤 I/O를 순차 I/O로 변환해 성능을 향상시킨다.
  - 압축: 인덱스는 기본적으로 프리픽스 압축(prefix compression) 지원
    - 인덱스 키들의 공통 접두사 부분을 압축해 저장 공간을 절감한다.
- 로컬 인덱스
  - 샤딩 클러스터 환경에서 각 샤드가 자신이 저장하고 있는 도큐먼트에 대해서만 관리하는 인덱스를 의미한다.
  - 특징
    - 각 샤드는 자신의 데이터에 대해 별도로 인덱스를 생성·관리한다.
    - 인덱스가 저장하고 있는 도큐먼트들은 해당 샤드 내에 물리적으로 존재하는 데이터에 한정된다.
    - 애플리케이션 레벨에서 전역 유니크성을 보장해야 한다.
      - 샤딩 환경에서 유니크 인덱스나 프라이머리 키 인덱스가 있다면 반드시 샤드 키를 포함하는 등의 방법 필요
  - 의미
    - 샤딩된 컬렉션은 데이터가 여러 샤드에 분산 저장되므로, 인덱스 역시 각 샤드별로 로컬하게 존재하고 관리된다.
    - 샤드간의 인덱스 통합 구조가 아니라 각자 독립적인 인덱스를 갖는다.
  - 제한 사항
    - 전역 유니크 인덱스는 기본적으로 지원하지 않으며, 이를 위해 샤드 키와 연계하거나 외부에서 중복 체크를 해야 한다.
    - 인덱스가 많아질수록 밸런싱 속도와 시스템 부하에 영향을 줄 수 있다
- 인덱스 키 엔트리 자료구조
  - 키 값(Key): 인덱스를 생성할 때 지정한 필드의 값이 인덱스 키로 사용되며 BSON 타입으로 복합 인덱스인 경우 여러 필드가 조합되어 하나의 키를 형성
  - Record-Id (도큐먼트 위치 정보): 각 인덱스 키와 연결된 도큐먼트의 저장 위치를 의미한다.
    - MongoDB 내부적으로는 Record-Id로 관리되며, 도큐먼트의 논리적 위치 혹은 물리적 위치를 가리킨다.
  - 노드 종류
    - 브랜치 노드: 하위 노드들을 가리키는 인덱스 엔트리들을 포함한다.
    - 리프 노드: 실제 키와 Record-Id 쌍으로 구성되어, 도큐먼트 바로 접근이 가능하다.
  - 정렬: 키 값들은 B-Tree 특성상 정렬되어 저장되어 있어 빠른 탐색과 범위 쿼리가 가능하다.
  - 멀티 키 인덱스: 배열 필드를 인덱스할 때 하나의 도큐먼트에 여러 키 엔트리가 생성될 수 있다.
  - 동작 및 특징: 인덱스는 빠른 검색을 위해 키 값에 따라 정렬과 트리 탐색 구조를 유지한다.
    - Record-Id를 통해 인덱스에서 도큐먼트로 빠르게 접근 가능하며, 추가/삭제 시 B-Tree 노드가 분할/병합된다.
    - BSON 기반의 가변 길이 키 값을 처리하기 때문에 인덱스 키 엔트리 크기가 달라질 수 있다.

#### B-Tree 인덱스

#### Hash 인덱스

#### 멀티 키 인덱스

#### 인덱스 속성
- 프라이머리 키와 세컨드리 인덱스
  - 모든 컬렉션이 반드시 프라이머리 키를 갖으며 MongoDB의 프라이머리 키 필드는 사용자가 필드의 이름을 결정할 수 없다
    - 사용자가 필드의 이름을 결정할 수 없고 _id라는 이름의 도큐먼트에 저장해야 한다
  - 그 외에 인덱스는 세컨드리 인덱스라 한다.
  - 컬렉션이 샤딩 된 경우에는 각 샤드간 프라이머리 키 값의 중복 체크를 응용 프로그램에서 처리해야 한다
  - 서브 도큐먼트를 인덱스 키로 사용하는 경우 서브 도큐먼트의 필드 개수와 필드 이름, 값까지 같아야 같은 값으로 판단
    - 필드 개수나 순서와 관계없이 검색하고자 한다면 각 팔디를 조건에 명시하면 된다. 하지만 이렇게 할 경우 인덱스 조회를 못함
    - COLLSCAN 발생
    ```
    $ db.users.insert({"_id": {"birth_date": "1980-01-01", "name": "matt"}})
    $ db.users.insert({"_id": {"name": "matt", "birth_date": "1980-01-01"}})
    
    $ db.users.find({"_id.birth_date": "1980-01-01", "_id.name": "matt"})
    ```
- 유니크 인덱스
  ```
  $ db.unique.createIndex({"age": 1}, {unique: true})
  ```
  - 유니크 인덱스라고 해서 NULL 값이 제한되는 것은 아니며 프라이머리 키는 기본적으로 유니크 속성 부여
    - 하지만 NULL 값이 2개 이상일 수 없다.
  - MongoDB에는 유니크 인덱스는 도큐먼트 간의 중복된 값을 체크하지만 도큐먼트 내에서 중복된 값을 체크하지 않는다.
    - 서브 도큐먼트를 배열로 갖으면, 해당 필드를 유니크 인덱스가 있지만, 같은 번호를 저장해도 에러가 발생하지 않는다.
    ```
    $ db.users.createIndex({"contacts.no": 1}, {unique: true})
    $ db.users.insert({ name: "matt", contacts: [
      {type:"office", no: {"010-0000-0000"}, {type:"mobile", no: {"010-0000-0000"}}]});
    ```
  - 샤딩을 적용하지 않으면 유니크 인덱스를 생성할 수 있지만 샤딩에 경우 샤드키를 선행 필들르 가지는 인덱스에만 유니크 인덱스를 생성할 수 있다
- Partial 인덱스
  - Partial Index(부분 인덱스)는 컬렉션 내 도큐먼트 중에서 특정 조건에 부합하는 도큐먼트에 대해서만 인덱스를 생성
  - 주요 특징
    - 조건부 인덱스 생성: 인덱싱할 때 partialFilterExpression 옵션에 정의한 조건을 만족하는 도큐먼트만 인덱싱된다.
      ```
      $ db.collection.createIndex({score:1}, {partialFilterExpression:{score:{$gte:100}}})
      // score가 100 이상인 도큐먼트만 인덱스 엔트리 생성.
      ```
    - 스토리지 절약 및 성능 최적화: 전체 데이터가 아닌 일부 조건을 만족하는 데이터에만 인덱싱되므로 인덱스 크기가 대폭 줄고, 인덱스 관리(생성/갱신) 비용이 감소한다.
    - 복합 조건 가능: 필드 존재 여부($exists), 비교 연산($gt, $gte, $lt, $lte 등), 타입($type), 그리고 상위에 $and 연산자를 활용한 조건식도 지정할 수 있다.
  - 제약점
    - 샤드 키/Primary Key에 사용 불가: partial 인덱스는 샤드 키 인덱스나 _id(Primary Key) 인덱스는 지원하지 않는다.
    - 커버링 인덱스 제한: 쿼리가 partial 조건을 벗어나면 인덱스를 사용할 수 없고, 인덱스가 해당 쿼리를 커버하지 못함.
- Sparse 인덱스
  ```
  $ db.sparse.createIndex( {birth_date: 1}, {sparse: true} )
  ```
  - sparse index(희소 인덱스)는 인덱싱할 필드가 존재하는 도큐먼트에만 인덱스 엔트리를 생성하는 인덱스 옵션이다.
  - 핵심 특징
    - 필드 존재 조건: 인덱스 대상 필드가 컬렉션의 도큐먼트에 존재하면 인덱스 엔트리를 만들며, 해당 필드가 없는 도큐먼트는 인덱스에 포함되지 않는다.
    - NULL 값 처리 및 효율: 해당 값이 null인 경우나 필드가 아예 없는 경우 인덱싱하지 않아 저장 공간과 인덱싱 비용이 줄어든다.
      - 희소 인덱스는 유니크 인덱스와 조합할 경우, 필드가 없는 도큐먼트끼리의 중복을 허용한다.
    - 적용 시기: 컬렉션 내에 인덱싱 필드가 없는 도큐먼트가 상당수 있을 때, 쓸모 없는 인덱스 엔트리 생성을 방지해 효율적
  - 제약 및 주의점
    - 희소 인덱스가 걸린 필드는 쿼리 인덱스 최적화에는 좋지만, 컬렉션 전체에서 값을 반드시 커버하지 못한다.
      - 일부 쿼리 결과에 빠진 도큐먼트가 있을 수 있다.
    - 커버링 인덱스 성능 최적화가 제한될 수 있으며, 쿼리 힌트 사용 시 결과 불완전 가능성도 있다
- TTL(Time-To-Live) 인덱스
  ```
  db.logs.createIndex({ "createdAt": 1 }, { expireAfterSeconds: 3600 })
  // createdAt 기준 1시간(3600초) 후 도큐먼트 자동 삭제
  ```
  - TTL 인덱스는 컬렉션 내의 도큐먼트가 특정 시간이 지나면 자동으로 삭제되도록 하는 특수 인덱스 기능이다.
  - 핵심 특징
    - 자동 데이터 만료 및 삭제: Date 타입 필드(예: createdAt, expires 등)를 기준으로 정해진 시간이 지나면, 도큐먼트가 백그라운드에서 자동 삭제
    - 단일 필드만 적용: TTL 인덱스는 반드시 전용 날짜(Date) 필드에만 적용되며, 복합 인덱스에서는 지원하지 않는다.
    - 옵션 사용법: 인덱스 생성시 expireAfterSeconds 옵션을 명시해, 데이트 필드 기준 n초 후 도큐먼트를 삭제한다.
    - 백그라운드 동작: TTL 인덱스는 실시간이 아닌, 내부 스케줄러가 약 60초마다(최대 1분 지연) 만료 데이터를 삭제한다.
  - 활용 사례
    - 로그, 세션, 임시 인증 정보, 캐시 등 일정 시간 뒤 삭제가 필요한 데이터 관리에 많이 사용된다.
  - 주의사항
    - 타이머 기반이므로 Date 필드 값이 변경되면 TTL 타이머도 갱신된다. 대량 삭제 시 일시적으로 성능 영향을 받을 수 있다
- 외래키
  - 외래키에 대한 제약 기능을 지원하지 않는다.
  - 컬렉션이 샤딩을 가정하고 구현했기 때문에 외래 키에 대한 제약을 구현한다 하더라도 성능을 보장할 수 없기 때문
  - 외래 키에 대한 일관된 처리가 꼭 필요하다면 응용 프로그램에서 직접 구현하는 것 외에는 방법이 없다
