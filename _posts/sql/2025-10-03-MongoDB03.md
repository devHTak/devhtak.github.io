### 7장. 데이터 모델링

#### 데이터베이스와 컬렉션
- 네임스페이스
  - Mongo에서 네임스페이스는 데이터베이스 이름과 컬렉션 이름을 조합한 문자열로, 특정 컬렉션을 고유하게 식별하는 역할을 한다
  - <database>.<collection> 으로 네임스페이스로 각 객체의 관리 참조가 된다    
- 데이터베이스
  - RDB에서 데이터베이스 분리/통합은 성능보다는 샤딩이나 서비스 통합과 관련한 고려사항
    - 초기 버전에서는 데이터베이스 단위로 락이 걸렸기 때문에 성능과 관련이 있었지만, 2.2 버전 이후 글로벌 락(인스턴스락)이 개선되었다
    - MMAPv1 스토리지 엔진은 데이터베이스 수준의 락을 세분화하여 컬렉션 수준의 잠금으로 개선
    - WiredTiger 스토리지 엔진에 RDB 같이 도큐먼트(레코드) 수준의 잠금 제공
  - 데이터베이스에 새로운 컬렉션이나 인덱스를 추가/변경할 때에는 데이터베이스 수준의 잠금 필요
  - 맵 리듀스 작업도 마지막 단계에서 데이터베이스 수준의 잠금 필요
- 컬렉션
  - Mongo는 기본적으로 조인을 지원하지 않기 떄문에 컬렉션에 가능한 많은 데이터를 내장할 것을 권장하고 있다.
  - 모델링 측면에서는 맞을 수 있지만 성능 측면에서는 그렇지 않을 수 있다.
    - 컬렉션 크기가 커지면 그로 인해 많은 디스크 읽기 오퍼레이션 필요하며 캐시 효율이 떨어진다
  - MMAPv1 스토리지 엔진은 컬렉션 수준의 잠금을 제공
    - 쓰기 작업이 많이 발생할 경우 컬렉션을 분리하여 설계하는 것이 좋다
  - WiredTiger 스토리지 엔진에 경우 동시성 처리를 위해 DB, 컬렉션을 물리적으로 분리할 필요는 없다.
  - 컬렉션 설계에서 가장 중요한 것은 샤드 키 선정
- 뷰
  ```
  $ db.createView('view_name', 'collection_name', 'pipeline)
  ```
  - 복잡한 형태의 데이터 가공 로직을 캡슐화하여 접근 용이성 항상, 테이블의 일부 데이터에 대해서 접근 권한 허용하여 보안 강화의 목적으로 사용
    - 아직 구체화 뷰(Materialized View), 업데이트 가능 뷰(Updatable View)를 지원하지 않기 때문에 뷰를 자주 사용하면 성능 저하 발생 
- BSON 도큐먼트
  - Binary JSON 의 약자로 JSON 형태의 도큐먼트를 바이너리 포맷으로 인코딩한 도큐먼트
    - Lightweight: binary 타입을 사용하여 공간적인 절약과 네트워크 전송 시 빠르다
    - traversable: 복잡한 파싱 과정 없이 필요한 필드만 빠르게 찾아갈 수 있도록 만들어졌다
    - efficient: C언어의 primitive 타입을 사용하기 때문에 매우 빠르게 인코딩/디코딩 가능
  - BSON 기본 타입
    - BYTE, INT32, INT64, DOUBLE
- 제한 사항
  - Mongo에서는 JSON으로 표시되지만 BSON으로 변환하여 저장
  - BSON 도큐먼트 포맷의 대표적인 특성
    - 하나의 도큐먼트는 "{", "}"로 감싸지며 모든 원소는 키/쌍 구성, 중첩된 도큐먼트의 깊이는 100lv, 도큐먼트 최대 크기는 16MB 까지 지원
  - 기존 JSON 포맷은 훨씬 다양하기 때문에 그대로 Mongo에 사용할 수 있는지 호환성 테스트 필요
  - 도큐먼트의 크기 제한(16MB) 때문에 대용량 데이터를 저장할 때 크기 고려가 필요하며 크기를 고정한 이유는 성능 이슈 발생 가능성 때문

#### 데이터 타입
- BSON 데이터 타입
  - MongoDB는 다양한 데이터 타입을 지원하며, 각 타입은 특정한 용도와 특성을 가지고 있다. 주요 BSON 데이터 타입은 다음과 같다
    - ObjectId: 12바이트의 Binary Data 타입을 Primitive 타입으로 사용
    - Integer: 32비트 또는 64비트 정수 값을 나타내는 타입
      - Double: 부동 소수점 숫자 값을 나타내는 타입
    - Decimal128: 고정 소수점 숫자를 저장하는 타입 (금융 애플리케이션에 유용)
    - String: UTF-8 인코딩된 문자열 값을 나타내는 타입
    - Timestamp: 타임스탬프 값을 저장하는 타입 (주로 내부 용도로 사용) 
    - Date: 날짜와 시간을 나타내는 타입 (밀리초 단위로 저장)
      - 타임존 확인을 위해서는 자바스크립트로 타입존 Offset을 확인해볼 수 있다
    - Null: 값이 없음을 나타내는 타입
    - Boolean: true 또는 false 값을 나타내는 타입
    - Array: 값의 배열을 나타내는 타입    
    - Binary Data: 바이너리 데이터를 저장하는 타입 (예: 이미지, 파일 등)
    - Regular Expression: 정규 표현식을 저장하는 타입
- 데이터 타입 비교
  ```
  $ db.collection.find( { field: { $type: <BSON type> } } ) // 해당 타입의 도큐먼트만 조회 가능
  ```
  - Mongo에서는 한 필드의 서로 다른 데이터 타입의 값을 가질 수 있다.
  - $type 연산자를 사용하여 도큐먼트의 특정 필드가 어떤 데이터 타입인지 확인할 수 있다
- 필드 값의 비교 및 정렬
  - MinKey(mongo 내부 타입) < Null < 숫자형 < 문자열형 < Object < Array < BinData < ObjectId < Boolean < Date < Timestamp < 정규표현식 < MaxKey(mongo 내부 타입)
- 문자셋과 콜레이션
  - 문자셋 (Character Set)
    - 문자셋은 텍스트에 사용되는 문자(글자, 숫자, 기호 등)를 컴퓨터가 저장하고 처리할 수 있도록 숫자 코드(인코딩)에 매핑하는 규칙의 집합 
    - MongoDB는 기본적으로 모든 문자열 데이터를 저장할 때 UTF-8 인코딩 사용 
    - UTF-8은 유니코드(Unicode) 표준의 한 형태로, 전 세계 대부분의 언어(한국어, 영어, 일본어, 중국어 등)를 표현할 수 있어 국제화(Internationalization)에 가장 적합하다. 
    - 사용자가 별도로 설정할 필요가 없으며, 모든 문자열 데이터는 UTF-8로 처리 
  - 콜레이션 (Collation)
    - 콜레이션은 문자열 데이터를 비교하고 정렬하는 데 사용되는 언어별, 로케일별 규칙의 집합 
    - 문자열의 동등성 판단(검색) 및 정렬 순서는 단순히 문자 코드값(바이너리 비교)으로만 결정되지 않고, 언어의 관습에 따라 달라지기 때문에 중요. 
    - MongoDB의 기본 콜레이션은 'simple' 이라는 바이너리 비교(Binary Comparison). 이는 단순히 UTF-8 코드 값 순서대로 비교하므로, 대소문자나 악센트 등을 구분 
    - 콜레이션의 주요 역할 
      - 대소문자 구분 (Case Sensitivity): 'a'와 'A'를 같은 것으로 볼지 다른 것으로 볼지 결정 
      - 악센트 구분 (Accent Sensitivity): 'e'와 악센트가 붙은 'é'나 'è'를 같은 것으로 볼지 다른 것으로 볼지 결정 
      - 정렬 순서 (Sort Order): 특정 언어(예: 스웨덴어, 독일어)에서 문자를 정렬하는 고유한 순서를 따른다 
      - 숫자 문자열 정렬 (Numeric Ordering): '10'과 '2'를 문자열로 정렬하면 '10'이 '2'보다 앞에 오지만, 콜레이션을 사용하면 숫자처럼 인식하여 '2'가 '10'보다 앞에 오도록 정렬 가능 
    - 콜레이션 설정 방법
      ```
      $ db.createCollection("myCollection", {
            collation: { locale: "ko" }
        });
      ```
      - 콜레이션은 ICU(International Components for Unicode) 표준을 따르며, 주로 locale 매개변수를 사용하여 설정 
      - 컬렉션 생성 시: db.createCollection() 명령어로 컬렉션을 만들 때 기본 콜레이션 지정. 해당 컬렉션에 대한 모든 쿼리는 이 규칙을 따른다. 
      - 인덱스 생성 시: db.collection.createIndex() 명령어로 인덱스를 만들 때 콜레이션을 지정. 쿼리의 콜레이션이 인덱스의 콜레이션과 정확히 일치해야만 해당 인덱스를 사용하여 정렬 및 비교 성능을 최적화할 수 있다. 
      - 개별 연산 시: CRUD 작업 시 콜레이션을 지정하여 컬렉션의 기본 설정을 재정의할 수 있다.
- MongoDB 확장 JSON (Extended JSON)
  - 내부적으로 BSON의 일부 타입을 지원하기 때문에 mongo에서 생성된 JSON 도큐먼트를 다른 도구들이 인식하지 못하는 경우 발생
    - mongo의 JSON을 STRICT 모드와 mongo shell 모드로 구분하여 사용할 수 있다
  - STRICT 모드는 mongo 도구뿐만 아니라 외부의 모든 JSON 도구들이 JSON 도큐먼트를 파싱할 수 있다
    - 하지만 Binary, ObjectId와 같은 타입은 인식하지 못한다.
  - mongo shell 모드의 JSON 표기법을 사용하면 예외 발생

#### 모델링 고려 사항

- 도큐먼트 크기
  - 일반적으로 도큐먼트는 RDB의 레코드의 크기보다 큰 경우가 많다.
    - Document DB 특성 상 하나의 도큐먼트의 여러 데이터를 모아 저장하는 경우가 있는 것으로 보임
  - 최대 크기 제한
    - 단일 document의 최대 크기는 16MB로 고정되어 있다.
    - 16MB를 초과하는 파일, 이미지, 대용량 로그 등의 경우 GridFS를 활용해 여러 청크로 분산 저장해야 한다.
  - 성능 및 리소스
    - 큰 document는 조회, 수정, 저장 시 더 많은 RAM과 디스크 I/O가 필요하므로 성능 저하 문제가 발생할 수 있다.
    - read/write 시 불필요한 large field까지 모두 불러오게 되어 네트워크 대역폭과 전체 시스템의 부담으로 이어진다.
    - frequently accessed document 크기가 크면 working set이 RAM을 쉽게 초과하여, 디스크 접근 빈도가 늘어나 DB 성능에 직접적인 영향을 준다.
  - 스키마 설계 Best Practice
    - 필요한 정보만 document에 포함시키고, 불필요한 필드를 최소화한다.
    - 깊은 중첩(nesting)을 피하며, embedded document(역정규화)와 referenced document(정규화) 전략을 적절하게 섞는다.
    - 대형 배열, unbounded array는 도큐먼트 크기를 빠르게 증가시키므로, 배열 내 개수를 제어하거나 분할 설계를 적용해야 한다.
    - 인덱스 대상 필드를 신중히 선정하며, 모든 필드를 인덱싱하면 오버헤드가 커진다.
    - 성장 가능성이 높은 document 구조는 사전에 분리(분할) 설계를 고려한다.
  - 기타 참고사항
    - Object.bsonsize() 등 shell 함수로 BSON 크기를 직접 체크할 수 있다.
    - 도큐먼트 크기 제한은 디버깅이나 ETL, batch 작업에서도 자주 문제가 되므로, 예상 성장 패턴까지 감안한 모델링이 필요하다.

- 정규화와 역정규화
  - 정규화 (Document Referencing)
    - 관계형 DB의 "정규화"와 유사하게, 관련 데이터를 별도의 컬렉션(테이블)로 분리하고 필요할 때 참조(reference)하는 방식
      - 학생과 수강과목 데이터를 각각 독립된 컬렉션에 저장하고, 학생 도큐먼트에는 각 과목의 id만 리스트 형태로 저장
    - 장점
      - 데이터 중복 최소화(변경 발생 시 하나만 수정)
      - 데이터 일관성, 무결성 보장에 유리
      - 컬렉션(테이블)의 크기를 작게 유지 가능
    - 단점
      - 데이터 조회 시 여러 컬렉션을 조합해야 하므로 join(lookup) 비용 증가
      - MongoDB는 복잡한 join이나 조인 성능이 RDB에 비해 떨어지는 편이다.
    - 권장 사례
      - 큰 서브 도큐먼트, 자주 갱신되는 데이터, 즉각적 일관성 필요, 증가량 많은 데이터, 빠른 쓰기 필요
      - 쓰기나 수정이 잦고, 일관성·데이터 크기가 큰 경우 referencing이 더 적합합니다.
  - 역정규화 (Embedding)
    - 관련 데이터를 한 도큐먼트 안에 중첩(embedded) 형태로 직접 포함시키는 방식
      - 학생 도큐먼트 내에 수강과목 정보를 배열로 직접 포함(예시: { classes: [{ class: "이산수학" }, ...] }).
    - 장점
      - 조회 시 필요한 데이터가 한 번에 로드되어 읽기 성능(쿼리 효율)이 좋음
      - 데이터 구조가 간단해져 복합 쿼리를 줄일 수 있음
      - join이 필요없는 구조이므로 빠른 read에 최적화
    - 단점
      - 데이터 중복 증가(같은 정보가 여러 문서에 있음)
      - 일관성 관리가 어렵고, 데이터 갱신 시 여러 문서를 동시 수정 필요
      - 단일 도큐먼트 최대 크기(16MB) 제한에 주의 필요
    - 권장 사례
      - 작은 서브 도큐먼트, 자주 변하지 않는 데이터, 결과적 일관성 허용, 증가량 적은 데이터, 빠른 읽기 필요
      - 읽기 빈도가 높고, 데이터 변경이 적거나 크기가 작으면 embedding을 추천합니다.

- 서브 도큐먼트
  - 갱신 패턴과 단편화 문제
    - 도큐먼트 갱신은 항상 전체 도큐먼트 단위(atomic)로 이뤄진다.
    - 서브 도큐먼트가 빈번히 추가/삭제/변경되면, 내부적으로 단편화(fragmentation)가 심화되어 성능 저하 발생
    - 주기적 갱신이 많은 데이터는 Reference(정규화) 방식이 더 적합하다.
  - 데이터 액세스 패턴
    - 서브 도큐먼트가 항상 부모 도큐먼트와 함께 조회된다면 embedding이 이상적이다.
    - 반면, 독립 조회나 별도 join이 빈번하다면 referencing이 효율적일 수 있다.
  - 일관성과 중복
    - embedded 구조는 데이터 일관성 유지가 쉽지 않다. 부모 도큐먼트가 여러 곳에 중복 저장될 수 있으므로, 일괄 갱신이 어렵다.
    - 자주 변하지 않는 데이터, 작은 정적 데이터(코드, 속성 등)에 적합하다.
  - 배열의 크기와 관리
    - 큰 배열이나 크기가 계속 증가하는 embedded array는 도큐먼트 크기 한계에 가까워질 수 있다.
    - 배치가 필요하거나 배열이 무제한적으로 늘어날 수 있다면, 별도 컬렉션에 저장 후 referencing을 권장한다.
  - 인덱싱과 쿼리 성능
    - 서브 도큐먼트 내 필드도 인덱스 생성 가능하지만, 지나치게 깊은 중첩은 인덱스 성능에 영향을 줄 수 있다.
    - 주로 사용하는 쿼리 조건과 인덱스 구성을 미리 설계해야 한다.
    - 정리하면, 서브 도큐먼트 구조는 데이터의 라이프사이클, 크기, 변경 빈도, 접근 패턴, 일관성 요구, 쿼리의 효율성을 모두 종합적으로 고려하여 설계해야 한다.
    - 불필요한 대형 도큐먼트 생성을 피하고 유지보수와 성능 모두를 균형 있게 신경 쓰는 것이 중요
 
- 배열
  - RDB에서는 다른 형태의 데이터를 저장할 수 없고 배열같은 타입은 정규화를 통해 해결한다.
  - Mongo는 배열 타입을 가질 수 있으며 멀티키를 통해 인덱스도 가능하다.
  - 또한 단일 도큐먼트 내에서만 원자성을 보장하기 때문에 배열 타입은 트랜잭션이 지원하지 않는 단점을 보완해준다
  - 도큐먼트 크기 증가
    - 만약 하나의 게시물 도큐먼트의 댓글을 배열로 저장하면 도큐먼트의 크기는 계속 증가하게 되며 이는 디스크나 메모리, CPU 자원 낭비 발생
  - 배열 관련 연산자 선택
    - $push, $pop
      - 배열 타입에 저장된 모든 아이템을 비교하지 않아도 되어 빠른 처리 가능
    - $addToSet, $pull($pullAll)
      - 기존 배열에 있는지/없는지 확인해야 하므로 배열의 모든 아이템과 비교 작업 수행
  - 배열과 복제
    - 가용성을 높이기 위해 레플리카셋을 활용하여 동일한 데이터 복제본을 갖게 되며 복제를 위해 oplog 사용
    - 복제 방식
      - 모든 데이터 변경은 Primary 노드에서만 이루어지며, 세부적 오퍼레이션 단위로 OpLog에 기록
      - 배열 내 원소의 추가, 삭제, 수정 같은 배열 연산도 OpLog에 개별 오퍼레이션 형태로 남는다.
      - Secondary 멤버는 OpLog의 각 엔트리를 읽어 원본과 동일하게 배열 연산도 순서대로 적용한다.
      - OpLog에는 "update" 오퍼레이션 발생하면,
        - 업데이트 명령(예: 배열 추가 시 $push, $addToSet, $pull 등)이 실제 쿼리 조건 및 변경된 데이터와 함께 저장
    - 일관성과 최종 상태
      - 모든 도큐먼트 복제는 최종 일관성 모델을 보장
        - 네트워크 이상 없이 충분히 시간이 지나면 모든 레플리카 노드의 배열 필드 내용도 Primary와 정확히 일치
      - 배열 크기나 배열의 경우에도 단일 document 크기(16MB) 제한은 그대로 적용된다.
    - 배열 필드 복제 관련 유의점
      - document-level 복제이므로, 배열 필드가 크거나 변경이 잦을수록 OpLog 사이즈와 Secondary 동기화 부하가 커진다.
      - 대규모 배열 변경(배열 교체, 전체 삭제 등)은 diff가 아닌 전체 값 교체로 기록될 수 있다.
      - 복제 실패나 재동기화 시에는 전체 document가 다시 복제된다.
- 필드 이름
  - mongo는 스키마를 갖지 않기 때문에 필드명을 정의할 필요 없이 필드명-필드값을 key-value 쌍으로 데이터 저장
  - 즉, 필드명도 데이터의 일부가 되고, 필드의 이름이 차지하는 공간이 크면 데이터의 크기 또한 커진다
- 프레그멘테이션과 패딩
  - 도큐먼트 단편화(Fragmentation)
    - 도큐먼트가 반복적으로 갱신·확장되어 크기가 커질 경우, 기존 저장 공간에 다 들어가지 못하면 WiredTiger(storage engine)는 새로운 위치에 저장하고 원래 공간은 미사용(unallocated) 처리
    - 이런 미사용 공간이 누적되면, 디스크에 큰 단편화가 발생하며, 읽기 및 저장 효율이 계속 떨어진다.
    - 잦은 배열/서브도큐먼트 추가, 값 확장, remove & insert 등이 심한 데이터에서 단편화 문제가 주로 발생한다.
  - 패딩(Padding) 정책
    - 패딩은 도큐먼트가 늘어날 것을 예상해, 실제 저장 시 추가 공간을 '버퍼'로 남겨두는 정책이다.
    - MMAPv1 엔진에서 자동 패딩을 적용했지만, WiredTiger는 기본적으로 패딩 없이 도큐먼트를 효율적으로 압축/저장한다.
    - 패딩이 없으면 도큐먼트 크기가 늘 때마다 공간이 부족해져 빈번한 재배치가 일어나고, 이는 곧 단편화로 연결된다.
  - 실전에서 고려할 점
    - 도큐먼트가 자주 커지는 데이터 구조(배열, 서브도큐먼트의 반복적 추가)는 최대 크기 예측과 더불어, 단편화 영향까지 설계 단계에서 신경 써야 한다.
    - 대형 배열, 주기적 구조 변동이 예상되면 정규화(Referencing)로 설계를 분산하는 것이 디스크 효율과 성능 관리에 유리하다.
    - 저장 공간 reclaim(회수)은 기본적으로 자동화되지 않으므로, 심각한 단편화가 누적된 경우 컬렉션 compact, reIndex, 데이터 마이그레이션 등의 운영 작업이 필요
    - WiredTiger는 단편화를 줄이기 위한 내부 압축과 공간 관리 기능을 제공
      - 그러나 구조적 단편화(모델링에서 오는 문제)는 사전에 설계로 예방하는 것이 가장 효율적이다.
- 도큐먼트 유효성 체크
  - 스키마 유효성 규칙 정의
    - MongoDB는 JSON Schema 기반 validation을 컬렉션 별로 적용할 수 있다.
    - 필수 필드 존재 확인, 타입 제약, 값 범위, 패턴(정규표현식), 중첩 구조 등 복잡한 조건을 스키마에 명시할 수 있다.
    - 변경 요구가 많은 환경은 너무 세밀한 규칙을 피하는 게 유리하다.
  - 성능 영향
    - 유효성 검사는 document insert/update 시마다 수행되므로, 복잡한 rule이 많으면 쓰기 성능이 저하될 수 있다.
    - 대량 데이터 입력·마이그레이션 시, validation 옵션을 일시적으로 해제할 필요도 있다.
  - 유연성 vs. 무결성의 균형
    -  NoSQL의 장점(유연함)을 살리되, 비즈니스 중요 정보는 꼭 validation rule을 적용해야 한다.
    -  버전 관리(스키마 진화) 상황에서는 규칙 변경·이관이 쉬운 구조로 설계하는 것이 편하다.
  - 운영 및 관리
    - 유효성 오류 발생 시 명확한 에러 메시지로 디버깅이 가능해야 하며, 개발/운영 환경별로 rule을 다르게 적용할 수도 있다.
    - 잘못된 데이터가 누적되지 않도록, validation 수준(서버의 strict, moderate, off 옵션), application 레이어에서의 복합 체크도 함께 고려한다.
- 조인
  - $lookup 사용 시 성능 이슈
    - MongoDB는 document 기반이며 native join은 없다.
    - 하지만 Aggregation Pipeline의 $lookup 스테이지를 사용해 컬렉션 간 조인을 구현할 수 있다.
    - $lookup은 별도의 컬렉션 전체 스캔(특히 인덱스가 없거나 join 키가 분산적일 경우)으로 인해, 대량 데이터/높은 QPS 환경에서 성능 저하가 발생할 수 있다.
    - join 대상이 커질 경우, 작업 시간이 길어지고 서버 리소스 소비가 매우 늘어난다.
  - 데이터 구조와 read/write 효율
    - 조인이 자주 발생하는 구조라면, 한 컬렉션에 embedding(역정규화)으로 데이터를 포함시키는 모델이 성능상 더 유리할 수 있다.
    - referencing(정규화)로 분할한 경우, join·lookup이 불가피하지만 데이터 중복은 최소화된다.
  - 인덱스 설계 필수
    - $lookup의 join 키(외래키 역할)는 반드시 인덱스를 생성해야 컬렉션 스캔을 막고 속도를 최대한 높일 수 있다.
    - join 빈도가 높은 필드는 단일 인덱스 혹은 복합 인덱스로 관리한다.
  - 확장성과 분산 환경
    - Sharding 환경에서는 $lookup 사용 시 제한과 구조적 제약이 있다. sharded collection 간의 lookup은 shard key, 데이터 분포에 따라 불가능하거나 성능 저하가 심할 수 있다.
    - 대형 서비스에서는 lookup을 최소화하고, embedding, application-side join(애플리케이션단에서 두 번 쿼리 후 병합) 등의 구조도 고려해야 한다.
  - 유지보수와 구조 변경
    - 데이터 모델 변경, 구조 진화 시 embedding과 referencing 전략의 전환이 요구될 수 있다.
    - 조인이 많아질수록 스키마 관리, 마이그레이션의 난이도가 높아진다.
    - 복잡한 multi-way join, 집계 join 등은 RDBMS 대비 구현/운영이 어렵다.

### 8장 쿼리 개발과 튜닝

### 9장 실행 계획 및 쿼리 최적화
- 세컨더리 인덱스를 지원하기 때문에 최소 1개 이상의 인덱스를 가질 수 있다
  - 조회 쿼리에서 어떤 인덱스를 사용하여 최적화를 할것인지, 그룹핑, 정렬 등에서도 인덱스에 대한 작업이 필요하다
 
#### 실행 계획
- 쿼리의 처리 과정
  - 일반적인 4개의 실행 계획을 트리 구조로 표현
    - fetch -> ixscan: 인덱스 레인지 스캐을 실행한 다음 컬렉션 데이터 파일에서 도큐먼트를 읽는 실행 계획
    - sort -> collscan: 컬렉션 풀 스캔으로 조건에 일치한 도큐먼트를 읽은 후 정렬을 수행하는 실행 계획
    - sort -> fetch -> ixscan: 인덱스 레인지 스캐을 실행하여 컬렉션 데이터 파일에서 도큐먼트를 읽고 정렬하는 실행 계획
    - fetch -> sort_merge -> (ixscan, ixscan)
      - 인덱스 인터섹션으로 레인지 스캔을 실행한 다음 컬렉션 데이터 파일에서 도큐먼트를 읽는 실행 계획
  - 실행 계획 트리는 최상위 스테이지를 루트라 하며, 자식 스테이지를 호출한다.
    - 각 스테이지를 호출하는 API의 이름이 work 라는 단어로 표현
    - work는 3종류(ADVANCE, NEED_TIME, IS_EOF)의 결과를 리턴한다.
      - ADVANCE: 스테이지의 처리 결과 한건의 도큐먼트/ID 반환
      - NEED_TIME: 처리는 완료됐지만, 결과 도큐먼트/ID 가 반환되진 않음(인덱스를 이용하여 읽었는데, 다른 조건에 의해 필터링)
      - IS_EOF: 처리 완료 및 더이상 읽을 데이터가 없는 경우
- 실행 계획 수립
  - 한번 실행했던 쿼리의 실행 계획은 캐시에 저장하고, 만약 같은 패턴의 쿼리가 다시 요청하면 재사용된다
    - 같은 쿼리인지 판단을 위해 Query Shape(3가지 정보 - 쿼리 조건, 정렬 조건, 조회 필드) 사용
  - 쿼리에서 실행 계획을 수립할 때
    - QueryShape 검색하여 있으면 캐싱된 쿼리 실행계획으로 쿼리 실행
    - QueryShape 검색하여 없으면 후보 실행 계획 수립, 평가, 최종 실행 계획 선택, 캐시 등록 후 쿼리 실행
  - 컬렉션이 삭제되거나 컬렉션의 인덱스 생성/삭제될 때 캐시된 실행계획은 모두 삭제된다
- 옵티마이저 옵션
  - internalQueryPlanEvaluationCollFraction(0,3), internalQueryPlanEvaluationWorks(10000) 옵션을 활용하여 실행계획 수립 과정에서 사용할 수 있는 최대 works 횟수 결정
  - works 함수 호출 횟수 내에 internalQueryPlanEvaludationMaxResults(101)로 설정된 건수만큼 도큐먼트 반환
  - internalQueryPlannerEnableIndexIntersection과 internalQueryPlannerEnableHashIntersection 옵션은 인덱스 인터섹션 최적화를 사용할 것인지 설정
    - Index Intersection(인덱스 교차)
      - 단일 쿼리에서 여러 필드가 검색 조건에 포함되어 있고, 각 필드에 각각 단일 인덱스가 존재할 때, MongoDB가 각각의 인덱스 결과를 내부적으로 교집합(AND) 연산하여 사용하는 기능이다.​
      - 장점: 복합 인덱스 없이 여러 인덱스의 조합도 활용 가능하므로, 인덱스 설계 유연성이 높아진다.
      - 제약: 복합 인덱스(compound index)에 비해 성능은 떨어질 수 있으며, 특정 정렬이나 복잡한 조건에서 사용 제한
    - Hash Intersection(AND_HASH)
      - 여러 인덱스의 결과를 해시 자료구조로 변환해, 각 인덱스의 결과집합 간 빠른 교집합 연산을 수행하는 내부 방식
      - 관련 유의사항
        - index intersection은 복합 인덱스가 모든 쿼리 조건을 커버하지 못하거나, 인덱스 개수가 너무 많아질 때 MongoDB가 자동 선택하는 절충적 방법이다.
        - 복합 인덱스를 잘 설계하면 더 빠르지만, 모든 조합을 커버하는 복합 인덱스가 어려운 경우 index intersection이 쿼리 효율을 높인다.​
- 플랜 캐시
  - 쿼리가 느리다면 실제 실행 계획을 수립하는 과정에서 많은 시간이 걸리기도 하며, 이렇게 플랜 캐시에 저장된 실행 계획은 아래 이벤트로 인해 삭제되기도 한다.
    - 인덱스가 생성/삭제되는 경우, reindex() 명령이 실행되는 경우, mongodb 가 재시작되는 경우
  - 2.6 버전 이전에는 쓰기 작업이 1000번 이상이면 실행 계획을 새로 수립하도록 했다(인덱스 분포도가 달라지기 떄문)
  - 3.0부터는 쓰기 횟수 상관없이 실행계획을 유지하고 쿼리가 실행될 때 간단히 평가하는 단계를 구현하여 성능이 나쁜 경우 실행계획을 다시 수집하는 방식으로 해결
  - PlanCache 객체와 관련된 기능 제공
    ```
    $ db.users.getPlanCache().listQueryShapes() // 컬렉션의 캐시된 실행 계획 확인
    $ db.users.getPlanCache().getPlansQyQuery({name: "Lara"}) // 해당 실행계획이 선택된 이유 확인
    $ db.users.getPlanCache().clear() // 플랜 캐시에 저장된 실행계획 전체 삭제
    $ db.users.getPlanCache().clearPlansByQuery({name: "Lara"}) // 플랜 캐시에 저장된 실행계획 삭제
    ```
- 실행계획 스테이지
  - collscan: 풀스캔 스테이지로 주어진 컬렉션으로부터 데이터를 읽어 출력만 만들어내는 스테이지
  - ixscan: 인덱스 레인지 스캔 접근 방식으로 데이터를 읽는 스테이지
  - queued_data: 컬렉션 없이 자체적으로 임시 데이터를 만드는 스테이지
  - fetch: 인덱스 레인지 스캔으로 읽은 인덱스 키와 record id 를 이용해 컬렉션의 도큐먼트를 읽는 스테이지
    - ixscan으로 부터 입력(record id)를 받아 도큐먼트를 출력으로 반환
  - keep_mutations: 인덱스 인터섹션 실행 계획을 사용. MMAPv1 스토리지 엔진에서 사용, WiredTiger에서는 사용하지 않음
  - and_sorted, and_hash: 인덱스 인터섹션 계획을 사용할 때, 인덱스를 통해 읽은 도큐먼트의 교집합을 찾는다
  - sort_key_generator: 인덱스를 사용하지 못할 때 정렬 기준 필드를 먼저 추출하는 과정
  - count: 자식 스테이지에서 반환한 도큐먼트의 건수를 누적하는 스테이지
  - count_scan: db.collection.count() 명령이 인덱스를 사용할 수 있을 때의 스테이지
  - distinct_scan: 인덱스 레인지 스캐의 변형된 형태로 순차적으로 읽으면서 유니크한 값을 나타낼 때 부모 스테이지로 결과 반환
  - ensure_sorted: 자식 스테이지 결과가 정렬 기준에서 어긋나는 경우 버리는 처리 수행
  - group: aggregation $group 파이프라인을 위새 사용하는 스테이지
  - idhack: _id 필드를 동등 비교로 검색하는 쿼리
  - index_iterator: 인덱스 스캔을 이용하는 커서를 끝까지 인덱스 키를 읽는 스테이지
  - limit: limit 이 사용될 때 N건의 도큐먼트만 반환하는 스테이지
  - skip: skip이 사용되는 경우 M건의 도큐먼트를 버리고 나머지를 반환
  - sort_merge: 두개 이상의 자식 노드(스테이지)에서 반환된 결과 집합을 병합
  - multi_iterator: 병렬 컬랙션 쿼리 나 RepairCursor에서 사용되는 스테이지
  - sharding_filter: 샤드된 데이터에서 청크 범위 외에 고아 도큐먼트를 가질 수 있는데, 이런 고아 도큐먼트를 필터링해서 버림
  - sort: 인덱스를 이용하지 못하는 정렬처리를 위해서 쿼리 실행 시점에 도큐먼트 정렬 수행
  - text, text_match, text_or:: 쿼리의 전문 검색 조건
  - update: update 명령을 처리하는 스테이지
  - delete: delete 명령 처리 스테이지
- 쿼리 실행 계획 해석
  - queryPlanner: 디폴트 값으로 최적의 실행 계획을 보이며 가장 단순한 형태
    - winningPlans: 선택된 최적 실행 계획, rejectedPlans: 버려진 실행 계획
    - queryPlanner 하위 스테이지는 왜 인덱스를 사용하는 지, 왜 정렬을 사용하는지 등의 내용 표현
    - 실제 트리 형태로 스테이지가 나타나며 부모 스테이지에서 자식 스테이지로 나타난다.
    - 실제 자식 스테이지부터 부모 스테이지 방향으로 실행된다.
  - executionStats: queryPlanner 모드의 모든 내용을 포함하며 최적 실행 계획과 실행 내역을 보여준다
    - executionStages 필드에 표시되는 스테이지를 처리하기 위해 work 함수가 몇번 호출됐고, 반환 등의 상세 정보 표현
    - stage: 현재 스테이지 타입
    - nReturned: 부모 스테이지로 반환된 결과 건수
    - executionTimeMillisEstimate: 자식 스테이지를 포함한 현재 스테이지 처리 시간
    - works: 현재 스테이지에서 호출된 work 수
    - needTime: 현재 스테이지에서 반환하지 못한 건수
    - needYield 현재 스테이지에서 yield 실행 건수
    - isEOF: 현재 스테이지에서 eof가 반환 여부
    - executionTimeMillisEstimated: 현재 스테이지 처리 시간
  - allPlansExecution: 최적 실행 계획과 그 상세 내역, 나머지 후보 실행 계획들의 내용도 포함
    - executionStages 를 배열로 표현되며 각 후보 실행 계획의 상태 정보 출력
- update와 remove 그리고 aggregation 쿼리의 실행 계획
  ```
  $ db.users.explain("queryPlanner").update({name: "6094"}, {$set: {fd: 1}})
  $ db.users.explain("queryPlanner").remove({name: "6094"})
  $ db.collections.aggregate([], {explain: true})
  $ db.collection.explain().aggregate()
  ```
  - 이런 형태로 실행 계획을 실행할 수 있다.

#### 쿼리 최적화
- 실행 계획의 쿼리 튜닝 포인트
  - 쿼리가 인덱스를 사용하는 지
    - COLLSCAN 스테이지가 아닌 IXSCAN이 발생하도록 하는 것이 중요
  - 도큐먼트 정렬이 인덱스를 사용하는 지
    - RDB처럼 정렬 순서가 인덱스 순서대로 데이터를 반환하기 때문에 별도 정렬처리를 제외할 수 있다.
    - 만약 그렇지 않으면 SORT 스테이지에서 도큐먼트를 정렬하는 단계를 거친다.
  - 필드 프로젝션이 인덱스르 사용(커버링 인덱스) 하는 지
    - 인덱스를 통해 RecordId를 검색하고, 실제 컬렉션 데이터 파일에서 해당 도큐먼트를 찾는 랜덤 액세스 방식으로 처리
    - 만약 필요한 필드가 인덱스에만 있는 경우 인덱스 스캔으로만 해결 가능(fetch 스테이지가 있는지, 없는지)
  - 인덱스 키 엔트리와 도큐먼트를 얼마나 읽었는 지
    - totalKeyExamined, totalDocsExamined 필드 값은 쿼리가 처리되면서 읽은 인덱스 키와 도큐먼트 개수 의미
    - totalKeyExamined 필드 값이 조금 높은 수치는 괜찮은 성능을 보이지만 totalDocsExamined 값이 높다면 튜닝이 필요할 수 있다.
  - 인덱스의 선택도는 얼마나 좋은 지
    - 실행계획에서 사용되는 인덱스가 조건을 얼마나 커버하는 지 성능상 매우 종요 요소
    ```
    $ db.users.find({birth_year: 1990, user_type: "P"})
    ```
    - 만약 birth_year 만 인덱스가 되어 있다면 user_type 조건은 한건씩 도큐먼트를 읽어서 비교해야 한다
    - birth_year, user_type으로 복합 인덱스를 준비하면 더 빠른 성능을 보인다
    - 만약 대부분의 user_type이 P 라면 user_type + birth_year 복합인덱스는 큰 도움이 되지 않는다.
    - 즉, 인덱스의 각 필드가 쿼리 작업 범위를 줄일 수 있는지 확인 필요
    - find, update, remove 전체를 고려한 인덱스 설계 필요
  - 어떤 스테이지가 가장 많은 시간을 소모하는가
    - 각 스테이지는 자식 스테이지를 포함하여 자신이 실행되는 데 소요된 시간(executionTimeMillis)를 보여준다
    - 각 스테이지가 처리되는 데 걸린 시간을 계산하여 많이 걸린 스테지를 집중적으로 최적화할 수 있다
- 슬로우 쿼리 로그 분석 및 튜닝
  - mongo에서는 100 밀리초가 넘으면 로그 파일에 모두 로깅되며 100 밀리초는 서버에 설정된 기본값으로 slowMs 옵션 조정 가능
  - 로그 파일에 가장 중요한 값은 planSummary, keyExamined, docsExamined, numYields 값
    - planSummary는 collscan 또는 ixscan 이 발생했는 지 알 수 있다
    - keyExamined, docsExamined는 쿼리를 처리하기 위해 읽은 인덱스 키의 갯수와 도큐먼트 개수를 보여준다.
      - 이 두값의 차이를 비교하면 인덱스 효율성을 알 수 있다
    - numYields 는 쿼리가 장시간 실행되면서 다른 커넥션들이 쿼리를 실행할 수 있도록 잠금을 해제/획득하는 과정을 보여준다.
- 쿼리 프로파일링
  - 로그 파일에는 매우 많은 정보가 기록되며, 때로는 로그 파일로 슬로우 쿼리 로그 정보를 수집하는 것이 어려울 수 있다.
  - 쿼리 프로파일링 컬렉션(system.profile)에 저장된 슬로우 쿼리 로그의 프로파일링 정보를 샘플링
    ```
    $ db.system.profile.find().sort({$natural: -1}).pretty()
    ```
    - 1MB를 넘어서면 오래된 로그는 삭제하고 새로 발생한 슬로우 쿼리 로그 저장
    - system.profile 컬렉션의 슬로우 쿼리 로그를 확인할 때는, 역순으로 정렬해야 시간 순으로 볼 수 있다
    - system.profile 컬렉션이나 커맨드의 종류별로 필터링해서 슬로우 쿼리 로그를 확인할 수 있는 장점 제공
- 인덱스 힌트
  - mongo에서도 세컨드리 인덱스를 지원하며 쿼리 처리할 때 최적 인덱스를 선정하는 옵티마이저의 실행 계획 수립 단계를 거친다
  - 옵티마이저가 수립하는 계획이 최적이 아닐 수 있기 때문에 hint를 주어 다른 방향으로 유도할 수 있다.
    ```
    $ db.users.find({name: "matt"}).sort({score: 1).hint({score: 1, name: 1}).explain()
    $ db.users.find({name: "matt"}).sort({score: 1).hint("ix_score_name").explain()
    $ db.users.find({name: "matt"}).sort({score: 1).hint({$natural: 1}).explain() // 풀스캔 유도
    ```
  - 인덱스가 변경되면 응용 프로그램에서 사용되는 쿼리 문장의 인덱스 힌트도 같이 변경되어야 한다
